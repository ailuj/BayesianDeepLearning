{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_mcdrop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailuj/BayesianDeepLearning/blob/master/First_mcdrop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hj3loSrQqHcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Import and Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "OKVteeYkwhly",
        "colab_type": "code",
        "outputId": "48aed7e6-934d-49d2-9047-d2093e756d87",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ede6da06-392d-40c4-9bcf-9ca67c027d93\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ede6da06-392d-40c4-9bcf-9ca67c027d93\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"batuhanipekci\",\"key\":\"5d999081520e00512450c7712eb80936\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "NPGc3WnTw9EL",
        "colab_type": "code",
        "outputId": "fae287bb-72aa-4328-8cef-321045f95603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d wendykan/lending-club-loan-data \n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "zip_file = ZipFile('lending-club-loan-data.zip')\n",
        "zip_file.namelist()\n",
        "loan = pd.read_csv(zip_file.open('loan.csv'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading lending-club-loan-data.zip to /content\n",
            " 97% 233M/240M [00:06<00:00, 48.5MB/s]\n",
            "100% 240M/240M [00:06<00:00, 41.0MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCdzhEEKwyOE",
        "colab_type": "code",
        "outputId": "9c904d2e-47c1-4890-fede-9c069214b599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "loan = pd.read_csv(zip_file.open('loan.csv'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kv05rvaax02H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loan = loan[(loan['loan_status'] != 'Current')]\n",
        "import numpy as np\n",
        "def ifelse_pd(x, check, yes,no):\n",
        "  if x in check:\n",
        "    res = yes\n",
        "  else:\n",
        "    res = no\n",
        "  return(res)\n",
        "\n",
        "\n",
        "loan['binary'] = loan['loan_status'].apply(\n",
        "    lambda x: ifelse_pd(x,['Charged Off', 'Default',\n",
        "                          'Late (31-120 days)',\n",
        "                          'Does not meet the credit policy. Status:Charged Off'],'Default', 'Not_Default'))\n",
        "\n",
        "selected = loan[['total_pymnt', 'annual_inc', 'int_rate','revol_bal','loan_amnt','purpose','binary']]\n",
        "selected = pd.get_dummies(selected)\n",
        "\n",
        "selected = selected.dropna()\n",
        "data = selected.drop(columns = ['binary_Default', 'binary_Not_Default'])\n",
        "target = selected[['binary_Default', 'binary_Not_Default']]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puxPiHytzqjc",
        "colab_type": "code",
        "outputId": "98f2ba68-ccef-4ac4-f019-717473c543d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "cell_type": "code",
      "source": [
        "selected.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_pymnt</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>purpose_car</th>\n",
              "      <th>purpose_credit_card</th>\n",
              "      <th>purpose_debt_consolidation</th>\n",
              "      <th>purpose_educational</th>\n",
              "      <th>purpose_home_improvement</th>\n",
              "      <th>...</th>\n",
              "      <th>purpose_major_purchase</th>\n",
              "      <th>purpose_medical</th>\n",
              "      <th>purpose_moving</th>\n",
              "      <th>purpose_other</th>\n",
              "      <th>purpose_renewable_energy</th>\n",
              "      <th>purpose_small_business</th>\n",
              "      <th>purpose_vacation</th>\n",
              "      <th>purpose_wedding</th>\n",
              "      <th>binary_Default</th>\n",
              "      <th>binary_Not_Default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5861.071414</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>10.65</td>\n",
              "      <td>13648.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1008.710000</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>15.27</td>\n",
              "      <td>1687.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3003.653644</td>\n",
              "      <td>12252.0</td>\n",
              "      <td>15.96</td>\n",
              "      <td>2956.0</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12226.302212</td>\n",
              "      <td>49200.0</td>\n",
              "      <td>13.49</td>\n",
              "      <td>5598.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5631.377753</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>7963.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    total_pymnt  annual_inc  int_rate  revol_bal  loan_amnt  purpose_car  \\\n",
              "0   5861.071414     24000.0     10.65    13648.0     5000.0            0   \n",
              "1   1008.710000     30000.0     15.27     1687.0     2500.0            1   \n",
              "2   3003.653644     12252.0     15.96     2956.0     2400.0            0   \n",
              "3  12226.302212     49200.0     13.49     5598.0    10000.0            0   \n",
              "5   5631.377753     36000.0      7.90     7963.0     5000.0            0   \n",
              "\n",
              "   purpose_credit_card  purpose_debt_consolidation  purpose_educational  \\\n",
              "0                    1                           0                    0   \n",
              "1                    0                           0                    0   \n",
              "2                    0                           0                    0   \n",
              "3                    0                           0                    0   \n",
              "5                    0                           0                    0   \n",
              "\n",
              "   purpose_home_improvement         ...          purpose_major_purchase  \\\n",
              "0                         0         ...                               0   \n",
              "1                         0         ...                               0   \n",
              "2                         0         ...                               0   \n",
              "3                         0         ...                               0   \n",
              "5                         0         ...                               0   \n",
              "\n",
              "   purpose_medical  purpose_moving  purpose_other  purpose_renewable_energy  \\\n",
              "0                0               0              0                         0   \n",
              "1                0               0              0                         0   \n",
              "2                0               0              0                         0   \n",
              "3                0               0              1                         0   \n",
              "5                0               0              0                         0   \n",
              "\n",
              "   purpose_small_business  purpose_vacation  purpose_wedding  binary_Default  \\\n",
              "0                       0                 0                0               0   \n",
              "1                       0                 0                0               1   \n",
              "2                       1                 0                0               0   \n",
              "3                       0                 0                0               0   \n",
              "5                       0                 0                1               0   \n",
              "\n",
              "   binary_Not_Default  \n",
              "0                   1  \n",
              "1                   0  \n",
              "2                   1  \n",
              "3                   1  \n",
              "5                   1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "w_5AxQsByFYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
        "\n",
        "scaler_tr = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler_tr.transform(X_train)\n",
        "\n",
        "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
        "X_test = scaler_test.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTbK3uNjqMWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP Architecture"
      ]
    },
    {
      "metadata": {
        "id": "bNFcdOv2yF6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3364376b-6499-4fb6-f831-a3b8bce81bcd"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "import time"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "u89nES7rye4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dropout_prob = 0.20 # dropout should be between 0.05 and 0.5\n",
        "n_epochs = 100\n",
        "tau = 1.0\n",
        "\n",
        "n_hidden = [15,15] # 2 hidden layers, each with 15 nodes\n",
        "N = X_train.shape[0]\n",
        "input_dim = X_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "# If addditional regularizer\n",
        "# lengthscale = 1e-2\n",
        "# reg = lengthscale**2 * (1 - dropout) / (2. * N * tau)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rF0dm6z10DR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model, Input\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "\n",
        "def mlp(input_dim, n_hidden, dropout_prob, train_activation, MCDropout = False):\n",
        "  \n",
        "  ### The code used to be like this, but Keras doesn't allow Dropout in the output layer\n",
        "  \n",
        "  #model = Sequential()\n",
        "  #model.add(Dense(128, input_dim = X_train.shape[1], activation = train_activation))\n",
        "  #model.add(Dropout(dropout_prob)) ## End of input layer\n",
        "  #model.add(Dense(n_hidden[0], activation = train_activation)) ## First hidden layer \n",
        "  # We can consider adding a regularizer during regression problems\n",
        "  #for i in range(len(n_hidden)-1): ## Remaining hidden layers\n",
        "  #  model.add(Dropout(dropout_prob))\n",
        "  #  model.add(Dense(n_hidden[i+1], activation = train_activation))\n",
        "  #if MCDropout == True:\n",
        "  #  model.add(Dropout(dropout_prob)) ## Adding dropout before the output layer: Trick is here!\n",
        "  #model.add(Dense(output_dim, activation = 'softmax')) ## Output layer\n",
        "  \n",
        "  #return model\n",
        "\n",
        "  # New model\n",
        "  inputs = Input(shape=(X_train.shape[1],))\n",
        "  inter = Dropout(dropout_prob)(inputs, training=True)\n",
        "  inter = Dense(n_hidden[0], activation=train_activation)(inter)\n",
        "  for i in range(len(n_hidden) - 1):\n",
        "    inter = Dropout(dropout_prob)(inter, training=True)\n",
        "    inter = Dense(n_hidden[i+1], activation=train_activation)(inter)\n",
        "  if MCDropout == True:\n",
        "    inter = Dropout(dropout_prob)(inter, training=True)\n",
        "  outputs = Dense(y_train.shape[1],activation = 'softmax')(inter)\n",
        "  model = Model(inputs, outputs)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rst_B2YAsrAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # Usual MLP"
      ]
    },
    {
      "metadata": {
        "id": "gJrX0Rxx3QUp",
        "colab_type": "code",
        "outputId": "5dc892f0-b560-4014-a133-6cafeb341cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3536
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "model = mlp(input_dim = input_dim, n_hidden = n_hidden, \n",
        "            dropout_prob = dropout_prob, train_activation = 'relu',MCDropout = False)\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epochs, verbose=1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "191349/191349 [==============================] - 14s 74us/step - loss: 0.4072 - acc: 0.8159\n",
            "Epoch 2/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3691 - acc: 0.8344\n",
            "Epoch 3/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3518 - acc: 0.8413\n",
            "Epoch 4/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3397 - acc: 0.8473\n",
            "Epoch 5/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3318 - acc: 0.8511\n",
            "Epoch 6/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3242 - acc: 0.8563\n",
            "Epoch 7/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3197 - acc: 0.8598\n",
            "Epoch 8/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3184 - acc: 0.8601\n",
            "Epoch 9/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3156 - acc: 0.8617\n",
            "Epoch 10/100\n",
            "191349/191349 [==============================] - 13s 65us/step - loss: 0.3135 - acc: 0.8637\n",
            "Epoch 11/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3126 - acc: 0.8633\n",
            "Epoch 12/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3105 - acc: 0.8652\n",
            "Epoch 13/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3104 - acc: 0.8661\n",
            "Epoch 14/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3074 - acc: 0.8683\n",
            "Epoch 15/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3067 - acc: 0.8694\n",
            "Epoch 16/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3033 - acc: 0.8712\n",
            "Epoch 17/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.3008 - acc: 0.8732\n",
            "Epoch 18/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.3006 - acc: 0.8724\n",
            "Epoch 19/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2985 - acc: 0.8745\n",
            "Epoch 20/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2976 - acc: 0.8756\n",
            "Epoch 21/100\n",
            "191349/191349 [==============================] - 13s 65us/step - loss: 0.2975 - acc: 0.8761\n",
            "Epoch 22/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2956 - acc: 0.8772\n",
            "Epoch 23/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2934 - acc: 0.8791\n",
            "Epoch 24/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2922 - acc: 0.8791\n",
            "Epoch 25/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2890 - acc: 0.8817\n",
            "Epoch 26/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2900 - acc: 0.8813\n",
            "Epoch 27/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2884 - acc: 0.8827\n",
            "Epoch 28/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2869 - acc: 0.8829\n",
            "Epoch 29/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2871 - acc: 0.8836\n",
            "Epoch 30/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2863 - acc: 0.8839\n",
            "Epoch 31/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2858 - acc: 0.8846\n",
            "Epoch 32/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2830 - acc: 0.8852\n",
            "Epoch 33/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2852 - acc: 0.8853\n",
            "Epoch 34/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2815 - acc: 0.8867\n",
            "Epoch 35/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2837 - acc: 0.8846\n",
            "Epoch 36/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2821 - acc: 0.8866\n",
            "Epoch 37/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2822 - acc: 0.8859\n",
            "Epoch 38/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2804 - acc: 0.8868\n",
            "Epoch 39/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2812 - acc: 0.8865\n",
            "Epoch 40/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2802 - acc: 0.8870\n",
            "Epoch 41/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2815 - acc: 0.8858\n",
            "Epoch 42/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2817 - acc: 0.8862\n",
            "Epoch 43/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2810 - acc: 0.8872\n",
            "Epoch 44/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2815 - acc: 0.8861\n",
            "Epoch 45/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2811 - acc: 0.8867\n",
            "Epoch 46/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2797 - acc: 0.8879\n",
            "Epoch 47/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2797 - acc: 0.8878\n",
            "Epoch 48/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2791 - acc: 0.8885\n",
            "Epoch 49/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2799 - acc: 0.8876\n",
            "Epoch 50/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2801 - acc: 0.8867\n",
            "Epoch 51/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2799 - acc: 0.8883\n",
            "Epoch 52/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2796 - acc: 0.8879\n",
            "Epoch 53/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2796 - acc: 0.8876\n",
            "Epoch 54/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2787 - acc: 0.8883\n",
            "Epoch 55/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2771 - acc: 0.8893\n",
            "Epoch 56/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2787 - acc: 0.8885\n",
            "Epoch 57/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2795 - acc: 0.8881\n",
            "Epoch 58/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2786 - acc: 0.8883\n",
            "Epoch 59/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2780 - acc: 0.8878\n",
            "Epoch 60/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2784 - acc: 0.8884\n",
            "Epoch 61/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2772 - acc: 0.8887\n",
            "Epoch 62/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2768 - acc: 0.8894\n",
            "Epoch 63/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2771 - acc: 0.8894\n",
            "Epoch 64/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2760 - acc: 0.8896\n",
            "Epoch 65/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2773 - acc: 0.8894\n",
            "Epoch 66/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2773 - acc: 0.8888\n",
            "Epoch 67/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2763 - acc: 0.8899\n",
            "Epoch 68/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2767 - acc: 0.8900\n",
            "Epoch 69/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2760 - acc: 0.8899\n",
            "Epoch 70/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2769 - acc: 0.8892\n",
            "Epoch 71/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2774 - acc: 0.8899\n",
            "Epoch 72/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2767 - acc: 0.8902\n",
            "Epoch 73/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2756 - acc: 0.8904\n",
            "Epoch 74/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2762 - acc: 0.8903\n",
            "Epoch 75/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2772 - acc: 0.8897\n",
            "Epoch 76/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2755 - acc: 0.8904\n",
            "Epoch 77/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2757 - acc: 0.8899\n",
            "Epoch 78/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2763 - acc: 0.8903\n",
            "Epoch 79/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2776 - acc: 0.8893\n",
            "Epoch 80/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2749 - acc: 0.8913\n",
            "Epoch 81/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2770 - acc: 0.8891\n",
            "Epoch 82/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2775 - acc: 0.8894\n",
            "Epoch 83/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2755 - acc: 0.8906\n",
            "Epoch 84/100\n",
            "191349/191349 [==============================] - 12s 65us/step - loss: 0.2747 - acc: 0.8905\n",
            "Epoch 85/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2762 - acc: 0.8896\n",
            "Epoch 86/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2761 - acc: 0.8898\n",
            "Epoch 87/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2755 - acc: 0.8901\n",
            "Epoch 88/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2762 - acc: 0.8898\n",
            "Epoch 89/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2751 - acc: 0.8906\n",
            "Epoch 90/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2756 - acc: 0.8902\n",
            "Epoch 91/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2766 - acc: 0.8903\n",
            "Epoch 92/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2762 - acc: 0.8898\n",
            "Epoch 93/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2747 - acc: 0.8905\n",
            "Epoch 94/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2760 - acc: 0.8901\n",
            "Epoch 95/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2745 - acc: 0.8907\n",
            "Epoch 96/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2758 - acc: 0.8906\n",
            "Epoch 97/100\n",
            "191349/191349 [==============================] - 12s 62us/step - loss: 0.2751 - acc: 0.8910\n",
            "Epoch 98/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2759 - acc: 0.8902\n",
            "Epoch 99/100\n",
            "191349/191349 [==============================] - 12s 63us/step - loss: 0.2744 - acc: 0.8906\n",
            "Epoch 100/100\n",
            "191349/191349 [==============================] - 12s 64us/step - loss: 0.2742 - acc: 0.8905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb81196080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "_0qJsBhy0JlL",
        "colab_type": "code",
        "outputId": "b8693dec-eae7-4d8b-bf67-ed20507cc724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94247/94247 [==============================] - 3s 35us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BL6JC9Zg0sQH",
        "colab_type": "code",
        "outputId": "b63587b7-588f-4ab2-cc32-26a1f7cb5ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test,pred)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.919692893644511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "L-lhUKE_tbPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bayesian MLP with Dropout Trick"
      ]
    },
    {
      "metadata": {
        "id": "0XzlEedyEjVj",
        "colab_type": "code",
        "outputId": "ff0704d5-b718-4ee5-8704-f122f4729e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "model = mlp(input_dim = input_dim, n_hidden = n_hidden, \n",
        "            dropout_prob = dropout_prob, train_activation = 'relu', \n",
        "            MCDropout = True)\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epochs, verbose=0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb829499e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "LH9HadES1Azr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run the model T times, each time we obtain a different output.\n",
        "# Collect outputs. It is our distribution\n",
        "# Gal argues that this is the same thing as sampling from the posterior\n",
        "\n",
        "T = 100\n",
        "        \n",
        "probs = []\n",
        "for _ in range(T):\n",
        "    probs += [model.predict(X_test,verbose=0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UAkBJfb1Ee6",
        "colab_type": "code",
        "outputId": "57ccddeb-5870-4221-8205-85147e8b7f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predictive_mean = np.mean(probs, axis=0)\n",
        "predictive_variance = np.var(probs, axis=0)\n",
        "                                  \n",
        "l = 100 \n",
        "# I need to check out how to choose l and tau\n",
        "\n",
        "tau = l**2 * (1 - dropout_prob) / (2 * N * 1)\n",
        "predictive_variance += tau**-1\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9658339105646352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "eYDQ2p4Y9U5B",
        "colab_type": "code",
        "outputId": "da985e50-f270-4d91-c463-d31ff48ad045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test,predictive_mean)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9658339105646352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "wcaPaM62xZXe",
        "colab_type": "code",
        "outputId": "516fb43c-24e9-4371-92da-23a1cdc0ff29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12151
        }
      },
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.02703005, 0.9729699 ],\n",
              "        [0.43370053, 0.56629944],\n",
              "        [0.07842223, 0.92157775],\n",
              "        ...,\n",
              "        [0.80328125, 0.19671875],\n",
              "        [0.7300749 , 0.26992512],\n",
              "        [0.00992135, 0.9900787 ]], dtype=float32),\n",
              " array([[0.07976808, 0.92023194],\n",
              "        [0.5606283 , 0.43937168],\n",
              "        [0.02320495, 0.976795  ],\n",
              "        ...,\n",
              "        [0.11592176, 0.8840782 ],\n",
              "        [0.836718  , 0.16328196],\n",
              "        [0.01864277, 0.9813572 ]], dtype=float32),\n",
              " array([[0.04799726, 0.9520027 ],\n",
              "        [0.8256119 , 0.17438816],\n",
              "        [0.05911325, 0.9408868 ],\n",
              "        ...,\n",
              "        [0.54088885, 0.45911118],\n",
              "        [0.82743967, 0.1725603 ],\n",
              "        [0.22653343, 0.7734665 ]], dtype=float32),\n",
              " array([[0.07104732, 0.9289527 ],\n",
              "        [0.5449312 , 0.45506883],\n",
              "        [0.0064915 , 0.9935086 ],\n",
              "        ...,\n",
              "        [0.62459934, 0.3754006 ],\n",
              "        [0.8478918 , 0.15210822],\n",
              "        [0.01561419, 0.9843858 ]], dtype=float32),\n",
              " array([[0.04710552, 0.95289445],\n",
              "        [0.66064674, 0.33935332],\n",
              "        [0.05242541, 0.9475746 ],\n",
              "        ...,\n",
              "        [0.84940284, 0.15059716],\n",
              "        [0.5671476 , 0.43285236],\n",
              "        [0.00465063, 0.99534935]], dtype=float32),\n",
              " array([[0.10420521, 0.89579475],\n",
              "        [0.19871698, 0.801283  ],\n",
              "        [0.00538619, 0.9946138 ],\n",
              "        ...,\n",
              "        [0.61832196, 0.38167801],\n",
              "        [0.20052092, 0.7994791 ],\n",
              "        [0.00375791, 0.99624205]], dtype=float32),\n",
              " array([[0.06627673, 0.9337233 ],\n",
              "        [0.5761043 , 0.42389572],\n",
              "        [0.37682536, 0.62317467],\n",
              "        ...,\n",
              "        [0.32187316, 0.6781268 ],\n",
              "        [0.36075473, 0.63924533],\n",
              "        [0.00785725, 0.9921428 ]], dtype=float32),\n",
              " array([[0.06152955, 0.9384704 ],\n",
              "        [0.7304426 , 0.26955742],\n",
              "        [0.581243  , 0.418757  ],\n",
              "        ...,\n",
              "        [0.1096155 , 0.8903845 ],\n",
              "        [0.7127548 , 0.28724518],\n",
              "        [0.00992266, 0.99007726]], dtype=float32),\n",
              " array([[0.14148484, 0.85851514],\n",
              "        [0.720091  , 0.27990904],\n",
              "        [0.08250988, 0.9174902 ],\n",
              "        ...,\n",
              "        [0.79933435, 0.20066562],\n",
              "        [0.82714903, 0.17285094],\n",
              "        [0.01196981, 0.98803014]], dtype=float32),\n",
              " array([[0.02900632, 0.9709937 ],\n",
              "        [0.81191397, 0.18808609],\n",
              "        [0.5405035 , 0.45949653],\n",
              "        ...,\n",
              "        [0.6323906 , 0.36760935],\n",
              "        [0.7962072 , 0.20379286],\n",
              "        [0.03380294, 0.9661971 ]], dtype=float32),\n",
              " array([[0.20436081, 0.7956392 ],\n",
              "        [0.3880398 , 0.6119602 ],\n",
              "        [0.01933975, 0.98066026],\n",
              "        ...,\n",
              "        [0.80662966, 0.19337037],\n",
              "        [0.7995768 , 0.20042317],\n",
              "        [0.01114993, 0.98885006]], dtype=float32),\n",
              " array([[0.17207624, 0.8279238 ],\n",
              "        [0.6786833 , 0.32131675],\n",
              "        [0.01546514, 0.98453486],\n",
              "        ...,\n",
              "        [0.78271306, 0.21728691],\n",
              "        [0.8298835 , 0.1701165 ],\n",
              "        [0.1574136 , 0.8425864 ]], dtype=float32),\n",
              " array([[0.08190478, 0.9180952 ],\n",
              "        [0.6122806 , 0.38771942],\n",
              "        [0.38111034, 0.61888963],\n",
              "        ...,\n",
              "        [0.12355197, 0.876448  ],\n",
              "        [0.45143098, 0.548569  ],\n",
              "        [0.21471843, 0.7852816 ]], dtype=float32),\n",
              " array([[0.19833666, 0.8016634 ],\n",
              "        [0.5610428 , 0.4389572 ],\n",
              "        [0.18268362, 0.8173164 ],\n",
              "        ...,\n",
              "        [0.95303756, 0.04696244],\n",
              "        [0.83996886, 0.1600311 ],\n",
              "        [0.01757061, 0.9824294 ]], dtype=float32),\n",
              " array([[0.09619243, 0.9038076 ],\n",
              "        [0.5331009 , 0.46689907],\n",
              "        [0.02367963, 0.9763204 ],\n",
              "        ...,\n",
              "        [0.05701271, 0.94298726],\n",
              "        [0.71274173, 0.28725833],\n",
              "        [0.01900512, 0.9809949 ]], dtype=float32),\n",
              " array([[0.16621771, 0.83378226],\n",
              "        [0.491392  , 0.50860804],\n",
              "        [0.02383291, 0.9761671 ],\n",
              "        ...,\n",
              "        [0.5557628 , 0.44423717],\n",
              "        [0.7889768 , 0.21102321],\n",
              "        [0.0031179 , 0.9968821 ]], dtype=float32),\n",
              " array([[0.2521737 , 0.7478263 ],\n",
              "        [0.6742244 , 0.32577562],\n",
              "        [0.44254288, 0.5574571 ],\n",
              "        ...,\n",
              "        [0.6879966 , 0.31200334],\n",
              "        [0.8478032 , 0.15219685],\n",
              "        [0.0080604 , 0.9919396 ]], dtype=float32),\n",
              " array([[0.12346288, 0.8765371 ],\n",
              "        [0.6072013 , 0.39279878],\n",
              "        [0.02033943, 0.9796606 ],\n",
              "        ...,\n",
              "        [0.16294087, 0.83705914],\n",
              "        [0.8277942 , 0.17220579],\n",
              "        [0.00504244, 0.9949576 ]], dtype=float32),\n",
              " array([[0.25414753, 0.7458525 ],\n",
              "        [0.66246295, 0.33753702],\n",
              "        [0.40291855, 0.5970814 ],\n",
              "        ...,\n",
              "        [0.10376882, 0.8962312 ],\n",
              "        [0.8274226 , 0.1725774 ],\n",
              "        [0.15384309, 0.8461569 ]], dtype=float32),\n",
              " array([[0.03821798, 0.96178204],\n",
              "        [0.7810925 , 0.21890748],\n",
              "        [0.09927475, 0.90072525],\n",
              "        ...,\n",
              "        [0.17777091, 0.8222291 ],\n",
              "        [0.8088739 , 0.19112611],\n",
              "        [0.02435659, 0.97564334]], dtype=float32),\n",
              " array([[0.06823418, 0.9317658 ],\n",
              "        [0.8104264 , 0.18957362],\n",
              "        [0.00911132, 0.9908887 ],\n",
              "        ...,\n",
              "        [0.8672222 , 0.13277778],\n",
              "        [0.52807003, 0.47193   ],\n",
              "        [0.00720777, 0.99279225]], dtype=float32),\n",
              " array([[0.03988765, 0.96011233],\n",
              "        [0.7307547 , 0.26924533],\n",
              "        [0.04530318, 0.95469683],\n",
              "        ...,\n",
              "        [0.9478282 , 0.0521718 ],\n",
              "        [0.83680475, 0.16319522],\n",
              "        [0.01906329, 0.9809367 ]], dtype=float32),\n",
              " array([[0.1254784 , 0.8745216 ],\n",
              "        [0.5487861 , 0.45121393],\n",
              "        [0.01505437, 0.98494565],\n",
              "        ...,\n",
              "        [0.1320677 , 0.86793226],\n",
              "        [0.83677715, 0.16322286],\n",
              "        [0.27923933, 0.72076064]], dtype=float32),\n",
              " array([[0.06611187, 0.93388814],\n",
              "        [0.79003716, 0.20996284],\n",
              "        [0.3999795 , 0.60002047],\n",
              "        ...,\n",
              "        [0.73738354, 0.2626165 ],\n",
              "        [0.36120632, 0.6387937 ],\n",
              "        [0.03592363, 0.9640764 ]], dtype=float32),\n",
              " array([[0.09547532, 0.9045247 ],\n",
              "        [0.70652103, 0.29347897],\n",
              "        [0.00608081, 0.99391913],\n",
              "        ...,\n",
              "        [0.07884228, 0.9211578 ],\n",
              "        [0.8478784 , 0.1521216 ],\n",
              "        [0.0131543 , 0.98684573]], dtype=float32),\n",
              " array([[0.06470175, 0.93529826],\n",
              "        [0.39470965, 0.60529035],\n",
              "        [0.0103548 , 0.98964524],\n",
              "        ...,\n",
              "        [0.74361116, 0.25638884],\n",
              "        [0.6846429 , 0.31535706],\n",
              "        [0.13912731, 0.8608727 ]], dtype=float32),\n",
              " array([[0.04174696, 0.9582531 ],\n",
              "        [0.35704723, 0.6429528 ],\n",
              "        [0.08447841, 0.9155216 ],\n",
              "        ...,\n",
              "        [0.28824377, 0.7117562 ],\n",
              "        [0.836729  , 0.16327102],\n",
              "        [0.00984206, 0.9901579 ]], dtype=float32),\n",
              " array([[0.04435816, 0.95564187],\n",
              "        [0.42341533, 0.57658464],\n",
              "        [0.00569214, 0.99430794],\n",
              "        ...,\n",
              "        [0.37638026, 0.62361974],\n",
              "        [0.8274589 , 0.17254108],\n",
              "        [0.0040827 , 0.99591726]], dtype=float32),\n",
              " array([[0.02071388, 0.97928613],\n",
              "        [0.6617245 , 0.3382755 ],\n",
              "        [0.02185697, 0.978143  ],\n",
              "        ...,\n",
              "        [0.19890636, 0.80109364],\n",
              "        [0.84777874, 0.15222122],\n",
              "        [0.01000106, 0.989999  ]], dtype=float32),\n",
              " array([[0.16303094, 0.8369691 ],\n",
              "        [0.7181743 , 0.28182572],\n",
              "        [0.17515908, 0.8248409 ],\n",
              "        ...,\n",
              "        [0.79713917, 0.20286077],\n",
              "        [0.7759572 , 0.22404283],\n",
              "        [0.03634636, 0.9636537 ]], dtype=float32),\n",
              " array([[0.2352257 , 0.76477426],\n",
              "        [0.7003858 , 0.29961422],\n",
              "        [0.00826646, 0.99173355],\n",
              "        ...,\n",
              "        [0.4693124 , 0.5306876 ],\n",
              "        [0.77133167, 0.2286684 ],\n",
              "        [0.00771231, 0.99228776]], dtype=float32),\n",
              " array([[0.05060131, 0.9493987 ],\n",
              "        [0.80205053, 0.1979495 ],\n",
              "        [0.00961923, 0.9903807 ],\n",
              "        ...,\n",
              "        [0.85782415, 0.14217593],\n",
              "        [0.8181104 , 0.18188962],\n",
              "        [0.02477752, 0.97522247]], dtype=float32),\n",
              " array([[0.10645067, 0.8935493 ],\n",
              "        [0.5729192 , 0.42708087],\n",
              "        [0.03916549, 0.9608345 ],\n",
              "        ...,\n",
              "        [0.42891955, 0.57108045],\n",
              "        [0.6159623 , 0.38403767],\n",
              "        [0.02174513, 0.97825485]], dtype=float32),\n",
              " array([[0.04581374, 0.9541862 ],\n",
              "        [0.7283613 , 0.2716387 ],\n",
              "        [0.00297972, 0.9970203 ],\n",
              "        ...,\n",
              "        [0.8486154 , 0.15138462],\n",
              "        [0.7851842 , 0.21481578],\n",
              "        [0.001904  , 0.99809605]], dtype=float32),\n",
              " array([[0.02787642, 0.97212356],\n",
              "        [0.73303276, 0.2669672 ],\n",
              "        [0.03888615, 0.9611138 ],\n",
              "        ...,\n",
              "        [0.6179449 , 0.3820551 ],\n",
              "        [0.4539307 , 0.5460693 ],\n",
              "        [0.00188864, 0.99811137]], dtype=float32),\n",
              " array([[0.01643154, 0.9835685 ],\n",
              "        [0.31517676, 0.6848232 ],\n",
              "        [0.00625898, 0.993741  ],\n",
              "        ...,\n",
              "        [0.9362984 , 0.06370166],\n",
              "        [0.3467774 , 0.6532226 ],\n",
              "        [0.00859551, 0.9914044 ]], dtype=float32),\n",
              " array([[0.0931545 , 0.90684545],\n",
              "        [0.8055173 , 0.19448268],\n",
              "        [0.01031959, 0.98968035],\n",
              "        ...,\n",
              "        [0.44918224, 0.5508178 ],\n",
              "        [0.8017077 , 0.19829233],\n",
              "        [0.08201069, 0.91798925]], dtype=float32),\n",
              " array([[0.22097285, 0.77902716],\n",
              "        [0.6386092 , 0.36139077],\n",
              "        [0.00848931, 0.9915107 ],\n",
              "        ...,\n",
              "        [0.078568  , 0.92143196],\n",
              "        [0.80102706, 0.19897288],\n",
              "        [0.01128659, 0.9887134 ]], dtype=float32),\n",
              " array([[0.12844999, 0.87155   ],\n",
              "        [0.21811199, 0.78188807],\n",
              "        [0.10773689, 0.8922631 ],\n",
              "        ...,\n",
              "        [0.8990632 , 0.10093672],\n",
              "        [0.6800945 , 0.31990555],\n",
              "        [0.01312021, 0.9868797 ]], dtype=float32),\n",
              " array([[0.02517583, 0.9748242 ],\n",
              "        [0.2383227 , 0.7616773 ],\n",
              "        [0.00279495, 0.9972051 ],\n",
              "        ...,\n",
              "        [0.96666425, 0.0333357 ],\n",
              "        [0.5366501 , 0.4633499 ],\n",
              "        [0.00843552, 0.9915645 ]], dtype=float32),\n",
              " array([[0.04811089, 0.95188904],\n",
              "        [0.83542746, 0.16457258],\n",
              "        [0.11331516, 0.88668483],\n",
              "        ...,\n",
              "        [0.9485014 , 0.05149865],\n",
              "        [0.5366533 , 0.4633467 ],\n",
              "        [0.0062343 , 0.9937657 ]], dtype=float32),\n",
              " array([[0.07736205, 0.922638  ],\n",
              "        [0.5966164 , 0.40338364],\n",
              "        [0.01567739, 0.9843226 ],\n",
              "        ...,\n",
              "        [0.8759484 , 0.12405157],\n",
              "        [0.7550342 , 0.2449658 ],\n",
              "        [0.01794963, 0.9820503 ]], dtype=float32),\n",
              " array([[0.06887154, 0.93112844],\n",
              "        [0.74587715, 0.25412288],\n",
              "        [0.46712366, 0.5328764 ],\n",
              "        ...,\n",
              "        [0.2693452 , 0.7306548 ],\n",
              "        [0.8367861 , 0.16321391],\n",
              "        [0.09137492, 0.9086251 ]], dtype=float32),\n",
              " array([[0.07098199, 0.929018  ],\n",
              "        [0.80205846, 0.19794154],\n",
              "        [0.24467425, 0.7553257 ],\n",
              "        ...,\n",
              "        [0.40204892, 0.5979511 ],\n",
              "        [0.3796786 , 0.62032145],\n",
              "        [0.30262128, 0.6973787 ]], dtype=float32),\n",
              " array([[0.08639767, 0.91360235],\n",
              "        [0.7102902 , 0.2897098 ],\n",
              "        [0.00501635, 0.9949837 ],\n",
              "        ...,\n",
              "        [0.88218963, 0.11781039],\n",
              "        [0.43420595, 0.5657941 ],\n",
              "        [0.23025358, 0.7697464 ]], dtype=float32),\n",
              " array([[0.03388127, 0.96611875],\n",
              "        [0.6874241 , 0.31257585],\n",
              "        [0.02299576, 0.97700423],\n",
              "        ...,\n",
              "        [0.8969932 , 0.10300678],\n",
              "        [0.3881187 , 0.6118813 ],\n",
              "        [0.0652332 , 0.93476677]], dtype=float32),\n",
              " array([[0.16610737, 0.83389264],\n",
              "        [0.6976212 , 0.30237877],\n",
              "        [0.2541942 , 0.74580586],\n",
              "        ...,\n",
              "        [0.10585842, 0.89414155],\n",
              "        [0.69813186, 0.30186814],\n",
              "        [0.24296793, 0.7570321 ]], dtype=float32),\n",
              " array([[0.22521468, 0.77478534],\n",
              "        [0.5844901 , 0.41550988],\n",
              "        [0.00720403, 0.992796  ],\n",
              "        ...,\n",
              "        [0.80427426, 0.19572575],\n",
              "        [0.4536498 , 0.54635024],\n",
              "        [0.00970903, 0.99029094]], dtype=float32),\n",
              " array([[0.03414667, 0.96585333],\n",
              "        [0.65393066, 0.3460693 ],\n",
              "        [0.11599024, 0.8840097 ],\n",
              "        ...,\n",
              "        [0.5837975 , 0.4162025 ],\n",
              "        [0.83678114, 0.16321887],\n",
              "        [0.00683155, 0.9931685 ]], dtype=float32),\n",
              " array([[0.06452151, 0.9354785 ],\n",
              "        [0.73496026, 0.26503974],\n",
              "        [0.7046143 , 0.29538572],\n",
              "        ...,\n",
              "        [0.17381735, 0.8261827 ],\n",
              "        [0.71268284, 0.28731716],\n",
              "        [0.01593704, 0.9840629 ]], dtype=float32),\n",
              " array([[0.0183922 , 0.9816078 ],\n",
              "        [0.16179526, 0.83820474],\n",
              "        [0.00239405, 0.9976059 ],\n",
              "        ...,\n",
              "        [0.12896061, 0.87103945],\n",
              "        [0.5844484 , 0.41555163],\n",
              "        [0.01498215, 0.98501784]], dtype=float32),\n",
              " array([[0.04125115, 0.9587489 ],\n",
              "        [0.38766018, 0.6123398 ],\n",
              "        [0.05727232, 0.9427277 ],\n",
              "        ...,\n",
              "        [0.7662155 , 0.23378448],\n",
              "        [0.6070188 , 0.3929812 ],\n",
              "        [0.17197983, 0.8280202 ]], dtype=float32),\n",
              " array([[0.02588293, 0.97411704],\n",
              "        [0.58824456, 0.41175544],\n",
              "        [0.6231661 , 0.37683392],\n",
              "        ...,\n",
              "        [0.87519413, 0.12480587],\n",
              "        [0.81637156, 0.18362843],\n",
              "        [0.00363486, 0.9963651 ]], dtype=float32),\n",
              " array([[0.19056858, 0.80943143],\n",
              "        [0.72937185, 0.27062815],\n",
              "        [0.01509058, 0.9849095 ],\n",
              "        ...,\n",
              "        [0.9083454 , 0.09165454],\n",
              "        [0.6159477 , 0.38405225],\n",
              "        [0.00550873, 0.9944912 ]], dtype=float32),\n",
              " array([[0.00553154, 0.99446845],\n",
              "        [0.64647144, 0.35352862],\n",
              "        [0.10089294, 0.8991071 ],\n",
              "        ...,\n",
              "        [0.6722254 , 0.3277746 ],\n",
              "        [0.23361194, 0.76638806],\n",
              "        [0.01254734, 0.9874527 ]], dtype=float32),\n",
              " array([[0.0844681 , 0.91553193],\n",
              "        [0.8317331 , 0.16826689],\n",
              "        [0.0046022 , 0.99539775],\n",
              "        ...,\n",
              "        [0.8134033 , 0.18659669],\n",
              "        [0.79996645, 0.20003352],\n",
              "        [0.01486673, 0.9851333 ]], dtype=float32),\n",
              " array([[0.05675284, 0.94324714],\n",
              "        [0.6761662 , 0.32383385],\n",
              "        [0.00307559, 0.99692434],\n",
              "        ...,\n",
              "        [0.05971411, 0.94028586],\n",
              "        [0.6159384 , 0.3840616 ],\n",
              "        [0.00310384, 0.99689615]], dtype=float32),\n",
              " array([[0.06042897, 0.93957096],\n",
              "        [0.8171891 , 0.18281089],\n",
              "        [0.40904292, 0.5909571 ],\n",
              "        ...,\n",
              "        [0.33951733, 0.66048265],\n",
              "        [0.34807825, 0.65192175],\n",
              "        [0.00718578, 0.99281424]], dtype=float32),\n",
              " array([[0.06473944, 0.93526053],\n",
              "        [0.8123025 , 0.1876975 ],\n",
              "        [0.03382965, 0.9661704 ],\n",
              "        ...,\n",
              "        [0.40838245, 0.5916175 ],\n",
              "        [0.34016615, 0.6598339 ],\n",
              "        [0.02393173, 0.97606826]], dtype=float32),\n",
              " array([[0.0655035 , 0.9344965 ],\n",
              "        [0.79663885, 0.20336117],\n",
              "        [0.0121779 , 0.9878221 ],\n",
              "        ...,\n",
              "        [0.78719735, 0.21280262],\n",
              "        [0.39423516, 0.6057648 ],\n",
              "        [0.00617291, 0.99382704]], dtype=float32),\n",
              " array([[0.06710027, 0.9328997 ],\n",
              "        [0.74294835, 0.25705165],\n",
              "        [0.1481247 , 0.8518753 ],\n",
              "        ...,\n",
              "        [0.91293734, 0.08706267],\n",
              "        [0.6070211 , 0.3929789 ],\n",
              "        [0.00166931, 0.99833065]], dtype=float32),\n",
              " array([[0.06060468, 0.93939537],\n",
              "        [0.7268928 , 0.27310717],\n",
              "        [0.15384708, 0.84615296],\n",
              "        ...,\n",
              "        [0.5057818 , 0.49421817],\n",
              "        [0.8119123 , 0.1880877 ],\n",
              "        [0.02338762, 0.9766124 ]], dtype=float32),\n",
              " array([[0.05872777, 0.94127226],\n",
              "        [0.7438565 , 0.25614345],\n",
              "        [0.00595946, 0.99404055],\n",
              "        ...,\n",
              "        [0.79222065, 0.20777935],\n",
              "        [0.7870436 , 0.2129564 ],\n",
              "        [0.02562038, 0.97437966]], dtype=float32),\n",
              " array([[0.22886518, 0.7711348 ],\n",
              "        [0.8115791 , 0.18842094],\n",
              "        [0.348782  , 0.65121806],\n",
              "        ...,\n",
              "        [0.59738815, 0.40261188],\n",
              "        [0.8221089 , 0.17789109],\n",
              "        [0.00555548, 0.99444455]], dtype=float32),\n",
              " array([[0.05271471, 0.9472853 ],\n",
              "        [0.6060958 , 0.39390427],\n",
              "        [0.14997189, 0.85002816],\n",
              "        ...,\n",
              "        [0.49315834, 0.50684166],\n",
              "        [0.84791464, 0.15208529],\n",
              "        [0.00538224, 0.99461776]], dtype=float32),\n",
              " array([[0.06817406, 0.9318259 ],\n",
              "        [0.73217624, 0.26782376],\n",
              "        [0.12339696, 0.876603  ],\n",
              "        ...,\n",
              "        [0.9320284 , 0.06797154],\n",
              "        [0.79844123, 0.20155875],\n",
              "        [0.00712214, 0.9928779 ]], dtype=float32),\n",
              " array([[0.06220568, 0.9377943 ],\n",
              "        [0.6883321 , 0.31166792],\n",
              "        [0.01045391, 0.9895461 ],\n",
              "        ...,\n",
              "        [0.91841954, 0.08158042],\n",
              "        [0.6417716 , 0.35822836],\n",
              "        [0.00505278, 0.99494725]], dtype=float32),\n",
              " array([[0.08545624, 0.9145438 ],\n",
              "        [0.60377705, 0.39622295],\n",
              "        [0.0091982 , 0.9908019 ],\n",
              "        ...,\n",
              "        [0.9506122 , 0.04938784],\n",
              "        [0.8367057 , 0.16329432],\n",
              "        [0.2918227 , 0.7081773 ]], dtype=float32),\n",
              " array([[0.23371701, 0.766283  ],\n",
              "        [0.8221449 , 0.1778551 ],\n",
              "        [0.349014  , 0.65098596],\n",
              "        ...,\n",
              "        [0.22358488, 0.7764151 ],\n",
              "        [0.8479102 , 0.15208974],\n",
              "        [0.19464457, 0.8053554 ]], dtype=float32),\n",
              " array([[0.09989445, 0.90010554],\n",
              "        [0.17643583, 0.8235642 ],\n",
              "        [0.01016969, 0.9898303 ],\n",
              "        ...,\n",
              "        [0.97555375, 0.02444623],\n",
              "        [0.71549964, 0.2845004 ],\n",
              "        [0.00384448, 0.99615556]], dtype=float32),\n",
              " array([[0.05673247, 0.9432675 ],\n",
              "        [0.83545804, 0.16454193],\n",
              "        [0.01318338, 0.9868166 ],\n",
              "        ...,\n",
              "        [0.9496786 , 0.05032143],\n",
              "        [0.30690476, 0.69309527],\n",
              "        [0.00527103, 0.994729  ]], dtype=float32),\n",
              " array([[0.1044158 , 0.8955842 ],\n",
              "        [0.19299676, 0.8070032 ],\n",
              "        [0.13854356, 0.86145645],\n",
              "        ...,\n",
              "        [0.56744325, 0.43255678],\n",
              "        [0.8505701 , 0.14942987],\n",
              "        [0.01256999, 0.98743004]], dtype=float32),\n",
              " array([[0.10131112, 0.89868885],\n",
              "        [0.72197956, 0.2780205 ],\n",
              "        [0.01765501, 0.9823449 ],\n",
              "        ...,\n",
              "        [0.87107533, 0.1289247 ],\n",
              "        [0.65674305, 0.3432569 ],\n",
              "        [0.01595914, 0.98404086]], dtype=float32),\n",
              " array([[0.12098347, 0.8790166 ],\n",
              "        [0.728815  , 0.27118495],\n",
              "        [0.01528471, 0.9847152 ],\n",
              "        ...,\n",
              "        [0.33886158, 0.6611384 ],\n",
              "        [0.8170856 , 0.18291438],\n",
              "        [0.02318344, 0.9768166 ]], dtype=float32),\n",
              " array([[0.09768274, 0.9023172 ],\n",
              "        [0.48482314, 0.51517683],\n",
              "        [0.1611604 , 0.8388396 ],\n",
              "        ...,\n",
              "        [0.7889582 , 0.21104185],\n",
              "        [0.4132647 , 0.58673525],\n",
              "        [0.00425369, 0.9957463 ]], dtype=float32),\n",
              " array([[0.1771155 , 0.8228845 ],\n",
              "        [0.60719043, 0.3928096 ],\n",
              "        [0.00795442, 0.9920455 ],\n",
              "        ...,\n",
              "        [0.7699257 , 0.23007424],\n",
              "        [0.47340184, 0.5265982 ],\n",
              "        [0.00498765, 0.99501234]], dtype=float32),\n",
              " array([[0.06911552, 0.9308845 ],\n",
              "        [0.559095  , 0.44090495],\n",
              "        [0.05878025, 0.94121975],\n",
              "        ...,\n",
              "        [0.9592769 , 0.04072314],\n",
              "        [0.7125786 , 0.28742135],\n",
              "        [0.14674404, 0.853256  ]], dtype=float32),\n",
              " array([[0.06252082, 0.9374792 ],\n",
              "        [0.66287065, 0.33712932],\n",
              "        [0.13219905, 0.8678009 ],\n",
              "        ...,\n",
              "        [0.8159291 , 0.18407087],\n",
              "        [0.6606867 , 0.33931333],\n",
              "        [0.03088548, 0.96911454]], dtype=float32),\n",
              " array([[0.07392216, 0.9260778 ],\n",
              "        [0.16117066, 0.83882934],\n",
              "        [0.05294644, 0.9470535 ],\n",
              "        ...,\n",
              "        [0.7348081 , 0.26519188],\n",
              "        [0.80088973, 0.1991103 ],\n",
              "        [0.04486347, 0.95513654]], dtype=float32),\n",
              " array([[0.05894758, 0.94105244],\n",
              "        [0.23837008, 0.76162994],\n",
              "        [0.18776959, 0.81223047],\n",
              "        ...,\n",
              "        [0.11163718, 0.8883629 ],\n",
              "        [0.3384576 , 0.6615424 ],\n",
              "        [0.0148403 , 0.9851597 ]], dtype=float32),\n",
              " array([[0.08016703, 0.91983294],\n",
              "        [0.610952  , 0.38904795],\n",
              "        [0.01509256, 0.9849074 ],\n",
              "        ...,\n",
              "        [0.96315265, 0.03684739],\n",
              "        [0.8010612 , 0.1989388 ],\n",
              "        [0.00341911, 0.9965809 ]], dtype=float32),\n",
              " array([[0.07113168, 0.92886835],\n",
              "        [0.67851615, 0.3214838 ],\n",
              "        [0.00468943, 0.9953106 ],\n",
              "        ...,\n",
              "        [0.7950471 , 0.20495293],\n",
              "        [0.84790343, 0.1520966 ],\n",
              "        [0.0194904 , 0.98050964]], dtype=float32),\n",
              " array([[0.3072041 , 0.6927959 ],\n",
              "        [0.74634147, 0.25365853],\n",
              "        [0.00292943, 0.99707055],\n",
              "        ...,\n",
              "        [0.81331295, 0.1866871 ],\n",
              "        [0.8016624 , 0.19833761],\n",
              "        [0.01108219, 0.9889178 ]], dtype=float32),\n",
              " array([[0.21852708, 0.7814729 ],\n",
              "        [0.5845527 , 0.4154473 ],\n",
              "        [0.10320069, 0.8967993 ],\n",
              "        ...,\n",
              "        [0.881721  , 0.11827901],\n",
              "        [0.6090213 , 0.39097872],\n",
              "        [0.02091659, 0.97908336]], dtype=float32),\n",
              " array([[0.10658184, 0.8934182 ],\n",
              "        [0.30893904, 0.69106096],\n",
              "        [0.19209261, 0.80790746],\n",
              "        ...,\n",
              "        [0.5033314 , 0.49666858],\n",
              "        [0.60761285, 0.39238712],\n",
              "        [0.02315037, 0.9768496 ]], dtype=float32),\n",
              " array([[0.0699714 , 0.9300286 ],\n",
              "        [0.1713843 , 0.8286157 ],\n",
              "        [0.00314019, 0.9968598 ],\n",
              "        ...,\n",
              "        [0.8954705 , 0.10452948],\n",
              "        [0.84789675, 0.15210325],\n",
              "        [0.00611024, 0.9938897 ]], dtype=float32),\n",
              " array([[0.05882007, 0.94117993],\n",
              "        [0.6456767 , 0.3543233 ],\n",
              "        [0.64148045, 0.35851958],\n",
              "        ...,\n",
              "        [0.706195  , 0.293805  ],\n",
              "        [0.8353025 , 0.1646975 ],\n",
              "        [0.0143726 , 0.9856274 ]], dtype=float32),\n",
              " array([[0.05442343, 0.9455766 ],\n",
              "        [0.17125796, 0.828742  ],\n",
              "        [0.22665039, 0.7733496 ],\n",
              "        ...,\n",
              "        [0.77960014, 0.22039993],\n",
              "        [0.79660285, 0.20339717],\n",
              "        [0.00676986, 0.9932301 ]], dtype=float32),\n",
              " array([[0.1538926 , 0.84610736],\n",
              "        [0.23022507, 0.7697749 ],\n",
              "        [0.02789588, 0.9721041 ],\n",
              "        ...,\n",
              "        [0.8253726 , 0.17462741],\n",
              "        [0.5937763 , 0.40622365],\n",
              "        [0.02139037, 0.9786097 ]], dtype=float32),\n",
              " array([[0.05699082, 0.9430092 ],\n",
              "        [0.6733874 , 0.32661253],\n",
              "        [0.00456984, 0.9954301 ],\n",
              "        ...,\n",
              "        [0.13874239, 0.8612576 ],\n",
              "        [0.8479032 , 0.15209687],\n",
              "        [0.18363853, 0.8163615 ]], dtype=float32),\n",
              " array([[0.3072041 , 0.6927959 ],\n",
              "        [0.7216013 , 0.27839866],\n",
              "        [0.03828651, 0.96171343],\n",
              "        ...,\n",
              "        [0.42145896, 0.57854104],\n",
              "        [0.793097  , 0.20690298],\n",
              "        [0.02226925, 0.97773075]], dtype=float32),\n",
              " array([[0.22290698, 0.777093  ],\n",
              "        [0.59820205, 0.40179792],\n",
              "        [0.06918288, 0.9308172 ],\n",
              "        ...,\n",
              "        [0.6994184 , 0.30058157],\n",
              "        [0.7126498 , 0.2873502 ],\n",
              "        [0.15842655, 0.8415734 ]], dtype=float32),\n",
              " array([[0.05772339, 0.9422766 ],\n",
              "        [0.78904283, 0.21095711],\n",
              "        [0.25458732, 0.74541265],\n",
              "        ...,\n",
              "        [0.10042813, 0.89957184],\n",
              "        [0.36452737, 0.6354726 ],\n",
              "        [0.00906755, 0.99093246]], dtype=float32),\n",
              " array([[0.06299746, 0.93700254],\n",
              "        [0.1891483 , 0.8108517 ],\n",
              "        [0.3432495 , 0.65675044],\n",
              "        ...,\n",
              "        [0.15594478, 0.8440552 ],\n",
              "        [0.6187888 , 0.3812112 ],\n",
              "        [0.15502585, 0.8449741 ]], dtype=float32),\n",
              " array([[0.04096147, 0.9590385 ],\n",
              "        [0.15796207, 0.842038  ],\n",
              "        [0.01469418, 0.98530585],\n",
              "        ...,\n",
              "        [0.14031304, 0.859687  ],\n",
              "        [0.6984082 , 0.30159178],\n",
              "        [0.00569933, 0.9943006 ]], dtype=float32),\n",
              " array([[0.11649166, 0.8835084 ],\n",
              "        [0.7862401 , 0.21375994],\n",
              "        [0.11714399, 0.882856  ],\n",
              "        ...,\n",
              "        [0.44231182, 0.5576882 ],\n",
              "        [0.83678675, 0.1632133 ],\n",
              "        [0.00757144, 0.9924286 ]], dtype=float32),\n",
              " array([[0.23542978, 0.76457024],\n",
              "        [0.70172155, 0.29827845],\n",
              "        [0.00462732, 0.9953727 ],\n",
              "        ...,\n",
              "        [0.53346854, 0.46653143],\n",
              "        [0.4517796 , 0.5482204 ],\n",
              "        [0.05250706, 0.94749296]], dtype=float32),\n",
              " array([[0.00568062, 0.9943193 ],\n",
              "        [0.7800888 , 0.2199112 ],\n",
              "        [0.00416476, 0.9958352 ],\n",
              "        ...,\n",
              "        [0.89780086, 0.10219909],\n",
              "        [0.41133094, 0.58866906],\n",
              "        [0.04216125, 0.9578387 ]], dtype=float32),\n",
              " array([[0.07076228, 0.9292377 ],\n",
              "        [0.7291979 , 0.27080214],\n",
              "        [0.15474813, 0.84525186],\n",
              "        ...,\n",
              "        [0.08431725, 0.91568273],\n",
              "        [0.70441   , 0.29559   ],\n",
              "        [0.00906472, 0.99093527]], dtype=float32),\n",
              " array([[0.09181358, 0.9081864 ],\n",
              "        [0.7633678 , 0.23663223],\n",
              "        [0.01133496, 0.988665  ],\n",
              "        ...,\n",
              "        [0.14206654, 0.8579335 ],\n",
              "        [0.7759665 , 0.22403349],\n",
              "        [0.15498893, 0.84501106]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "6FqwI4qg6UCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c41ec57f-92d4-40a7-e615-4d3212442cab"
      },
      "cell_type": "code",
      "source": [
        "predictive_variance"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[47.842007, 47.842007],\n",
              "       [47.876347, 47.876347],\n",
              "       [47.86457 , 47.86457 ],\n",
              "       ...,\n",
              "       [47.93034 , 47.93034 ],\n",
              "       [47.868946, 47.868946],\n",
              "       [47.842712, 47.842712]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}