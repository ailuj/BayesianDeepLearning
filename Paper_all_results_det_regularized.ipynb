{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paper_all_results_det_regularized.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailuj/BayesianDeepLearning/blob/paper/Paper_all_results_det_regularized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C9uyVyt2s5Mq",
        "colab_type": "code",
        "outputId": "22eaa64e-2985-40d2-e0f8-c9b19ff328b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YoO-pMrlgdov",
        "colab_type": "code",
        "outputId": "de59a4c4-6ca8-455b-d6eb-fd6eebd50529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/data_sets\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_set_40k.csv    train_set_150k.csv\ttrain_set_240k.csv\n",
            "train_set_100k.csv  train_set_200k.csv\ttrain_set_60k.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TKhRgPkztNrT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_40k = pd.read_csv('/content/drive/My Drive/data_sets/test_set_40k.csv')\n",
        "train_60k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_60k.csv')\n",
        "train_100k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_100k.csv')\n",
        "train_150k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_150k.csv')\n",
        "train_200k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_200k.csv')\n",
        "train_240k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_240k.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVLRbu1Vlm-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full = train_240k.append(test_40k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37Yt0TZ2mZvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full = full[['int_rate','loan_amnt','purpose', 'profit_rate']]\n",
        "full_features = full[['int_rate','loan_amnt','purpose']]\n",
        "full_features = pd.get_dummies(full_features)\n",
        "full_target = full[['profit_rate']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VxAcqIltSQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(x):\n",
        "  from sklearn import preprocessing\n",
        "  x = x.dropna()\n",
        " \n",
        "  x_features = x[['int_rate','loan_amnt','purpose']]\n",
        "  x_features = pd.get_dummies(x_features)\n",
        "  x_target = x[['profit_rate']]\n",
        "\n",
        "  scaler_features = preprocessing.MinMaxScaler().fit(full_features)\n",
        "  x_features = scaler_features.transform(x_features)\n",
        "  \n",
        "  scaler_target = preprocessing.MinMaxScaler().fit(full_target)\n",
        "  x_target = scaler_target.transform(x_target)\n",
        "  \n",
        "  return (x_features, x_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_L6cIU8lbbeg",
        "colab_type": "code",
        "outputId": "cd7755c7-a8c0-4148-e983-4d7788bbee5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "((test_40k_features,test_40k_target),\n",
        " (train_60k_features,train_60k_target),\n",
        " (train_100k_features,train_100k_target),\n",
        " (train_150k_features,train_150k_target),\n",
        " (train_200k_features,train_200k_target),\n",
        " (train_240k_features,train_240k_target)) = (preprocess(test_40k), \n",
        "                                             preprocess(train_60k), \n",
        "                                             preprocess(train_100k), \n",
        "                                             preprocess(train_150k), \n",
        "                                             preprocess(train_200k), \n",
        "                                             preprocess(train_240k)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qi2RQYntc2CN",
        "colab_type": "code",
        "outputId": "8798c6ce-8b0b-474e-8740-0b15ae8cf1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "((test_40k_features.shape,test_40k_target.shape),\n",
        " (train_60k_features.shape,train_60k_target.shape),\n",
        " (train_100k_features.shape,train_100k_target.shape),\n",
        " (train_150k_features.shape,train_150k_target.shape),\n",
        " (train_200k_features.shape,train_200k_target.shape),\n",
        " (train_240k_features.shape,train_240k_target.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((40000, 16), (40000, 1)),\n",
              " ((65600, 16), (65600, 1)),\n",
              " ((105600, 16), (105600, 1)),\n",
              " ((155600, 16), (155600, 1)),\n",
              " ((205600, 16), (205600, 1)),\n",
              " ((245600, 16), (245600, 1)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "RH2IrD6eQH_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modeling\n"
      ]
    },
    {
      "metadata": {
        "id": "3F6LrpwHe46R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model as mcModel\n",
        "from keras import Input as mcInput\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def architecture(model_type, h_cells, n_hidden, input_dim, dropout_prob, reg):\n",
        "   \n",
        "  if model_type == 'deterministic_regularized':\n",
        "    from keras.models import Sequential \n",
        "    from keras.layers import Dropout \n",
        "    from keras.layers import Dense \n",
        "    \n",
        "    model2 = Sequential()\n",
        "    model2.add(Dropout(dropout_prob, input_shape=(input_dim,)))\n",
        "    model2.add(Dense(h_cells, activation='relu', W_regularizer=l2(reg)))\n",
        "    model2.add(Dropout(dropout_prob))\n",
        "    model2.add(Dense(h_cells, activation='relu', W_regularizer=l2(reg)))\n",
        "    model2.add(Dropout(dropout_prob))\n",
        "    model2.add(Dense(1))\n",
        "    return model2\n",
        "\n",
        "def model_runner(X_train, y_train, X_test=test_40k_features, y_test=test_40k_target,\n",
        "                 dropout_prob=0.20, n_epochs=100, tau=1.0, batch_size=500, \n",
        "                 lengthscale=1e-2, n_hidden=[100,100], h_cells=100):\n",
        "  \n",
        "  input_dim = X_train.shape[1]\n",
        "  N = X_train.shape[0]\n",
        "  reg = lengthscale**2 * (1 - dropout_prob) / (2. * N * tau)\n",
        "\n",
        "  \n",
        "  print('Regularized Deterministic NN fit')\n",
        "\n",
        "  model_det_regularized = architecture(model_type = 'deterministic_regularized', \n",
        "                                   h_cells= h_cells, n_hidden=n_hidden, input_dim=input_dim, \n",
        "                                  dropout_prob=dropout_prob, reg=reg)\n",
        " \n",
        "  model_det_regularized.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "  model_det_regularized.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epochs, verbose=1)\n",
        " \n",
        "  \n",
        "  \n",
        "  return model_det_regularized\n",
        "\n",
        "\n",
        "def predictor(model_det_regularized, \n",
        "              X_test=test_40k_features, y_test = test_40k_target, T = 1000):\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  import numpy as np\n",
        "  \n",
        "  \n",
        "  pred_det_regularized = model_det_regularized.predict(X_test, verbose=1)\n",
        "  mse_det_regularized = mean_squared_error(pred_det_regularized, y_test)\n",
        "  print(mse_det_regularized)\n",
        "        \n",
        "  \n",
        "  return pred_det_regularized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuNiKp0EQGwf",
        "colab_type": "code",
        "outputId": "aaf5198d-9c23-4054-8478-3cb892f773fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_regularized_60k = model_runner(train_60k_features, train_60k_target)\n",
        "pred_det_regularized_60k = predictor( model_det_regularized_60k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Regularized Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "65600/65600 [==============================] - 1s 19us/step - loss: 0.0674 - mean_absolute_error: 0.2049\n",
            "Epoch 2/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0513 - mean_absolute_error: 0.1790\n",
            "Epoch 3/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0503 - mean_absolute_error: 0.1770\n",
            "Epoch 4/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0498 - mean_absolute_error: 0.1763\n",
            "Epoch 5/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0494 - mean_absolute_error: 0.1751\n",
            "Epoch 6/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0493 - mean_absolute_error: 0.1750\n",
            "Epoch 7/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0491 - mean_absolute_error: 0.1747\n",
            "Epoch 8/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0489 - mean_absolute_error: 0.1743\n",
            "Epoch 9/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0489 - mean_absolute_error: 0.1739\n",
            "Epoch 10/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0486 - mean_absolute_error: 0.1735\n",
            "Epoch 11/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0487 - mean_absolute_error: 0.1739\n",
            "Epoch 12/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0486 - mean_absolute_error: 0.1738\n",
            "Epoch 13/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0484 - mean_absolute_error: 0.1732\n",
            "Epoch 14/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0485 - mean_absolute_error: 0.1735\n",
            "Epoch 15/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0483 - mean_absolute_error: 0.1733\n",
            "Epoch 16/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0483 - mean_absolute_error: 0.1731\n",
            "Epoch 17/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0484 - mean_absolute_error: 0.1736\n",
            "Epoch 18/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0483 - mean_absolute_error: 0.1730\n",
            "Epoch 19/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1730\n",
            "Epoch 20/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1729\n",
            "Epoch 21/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1731\n",
            "Epoch 22/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1731\n",
            "Epoch 23/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1726\n",
            "Epoch 24/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1729\n",
            "Epoch 25/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1721\n",
            "Epoch 26/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1727\n",
            "Epoch 27/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1726\n",
            "Epoch 28/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1730\n",
            "Epoch 29/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1728\n",
            "Epoch 30/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1724\n",
            "Epoch 31/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1730\n",
            "Epoch 32/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1724\n",
            "Epoch 33/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1729\n",
            "Epoch 34/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1725\n",
            "Epoch 35/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1726\n",
            "Epoch 36/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1723\n",
            "Epoch 37/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1724\n",
            "Epoch 38/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1725\n",
            "Epoch 39/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1725\n",
            "Epoch 40/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1723\n",
            "Epoch 41/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 42/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1726\n",
            "Epoch 43/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1722\n",
            "Epoch 44/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1726\n",
            "Epoch 45/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1726\n",
            "Epoch 46/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1721\n",
            "Epoch 47/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1722\n",
            "Epoch 48/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 49/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1721\n",
            "Epoch 50/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 51/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1722\n",
            "Epoch 52/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 53/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1725\n",
            "Epoch 54/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 55/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 56/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 57/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1719\n",
            "Epoch 58/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 59/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 60/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 61/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 62/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 63/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 64/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 65/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 66/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 67/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 68/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1721\n",
            "Epoch 69/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1721\n",
            "Epoch 70/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1719\n",
            "Epoch 71/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 72/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 73/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 74/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 75/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 76/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 77/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 78/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 79/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 80/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1717\n",
            "Epoch 81/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 82/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1717\n",
            "Epoch 83/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 84/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 85/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1717\n",
            "Epoch 86/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1722\n",
            "Epoch 87/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1716\n",
            "Epoch 88/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 89/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 90/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1716\n",
            "Epoch 91/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 92/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 93/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 94/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 95/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 96/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 97/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 98/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 99/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 100/100\n",
            "65600/65600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "40000/40000 [==============================] - 2s 38us/step\n",
            "0.04806642242918309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9zMdMMh1Apf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pickle\n",
        "outfile = open('pred_det_regularized_60k.pickle','wb')\n",
        "pickle.dump(pred_det_regularized_60k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_regularized_60k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VgFnGN6aQFZi",
        "colab_type": "code",
        "outputId": "1865e193-8212-4890-9443-ee487f415e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_regularized_100k = model_runner(train_100k_features, train_100k_target)\n",
        "pred_det_regularized_100k = predictor(model_det_regularized_100k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularized Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "105600/105600 [==============================] - 2s 16us/step - loss: 0.0621 - mean_absolute_error: 0.1962\n",
            "Epoch 2/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0504 - mean_absolute_error: 0.1770\n",
            "Epoch 3/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0496 - mean_absolute_error: 0.1753\n",
            "Epoch 4/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0490 - mean_absolute_error: 0.1743\n",
            "Epoch 5/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0488 - mean_absolute_error: 0.1741\n",
            "Epoch 6/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0488 - mean_absolute_error: 0.1740\n",
            "Epoch 7/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0486 - mean_absolute_error: 0.1735\n",
            "Epoch 8/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0484 - mean_absolute_error: 0.1731\n",
            "Epoch 9/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1727\n",
            "Epoch 10/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1728\n",
            "Epoch 11/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1728\n",
            "Epoch 12/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1725\n",
            "Epoch 13/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1725\n",
            "Epoch 14/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1725\n",
            "Epoch 15/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1726\n",
            "Epoch 16/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1722\n",
            "Epoch 17/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1722\n",
            "Epoch 18/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1725\n",
            "Epoch 19/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 20/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1722\n",
            "Epoch 21/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 22/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1720\n",
            "Epoch 23/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1719\n",
            "Epoch 24/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 25/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 26/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 27/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1719\n",
            "Epoch 28/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 29/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 30/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 31/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 32/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 33/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 34/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 35/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 36/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 37/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 38/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 39/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 40/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 41/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1714\n",
            "Epoch 42/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 43/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 44/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 45/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 46/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 47/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 48/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 49/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 50/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 51/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 52/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 53/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 54/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 55/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 56/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 57/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 58/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 59/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 60/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 61/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 62/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 63/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 64/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 65/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 66/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 67/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 68/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 69/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 70/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 71/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 72/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 73/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 74/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 75/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 76/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 77/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 78/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 79/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 80/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1711\n",
            "Epoch 81/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 82/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 83/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 84/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 85/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 86/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1712\n",
            "Epoch 87/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 88/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 89/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 90/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 91/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 92/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 93/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 94/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 95/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 96/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1712\n",
            "Epoch 97/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 98/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1711\n",
            "Epoch 99/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 100/100\n",
            "105600/105600 [==============================] - 1s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "40000/40000 [==============================] - 2s 38us/step\n",
            "0.0482512373185952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "drTF_nHG1aeB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pickle\n",
        "outfile = open('pred_det_regularized_100k.pickle','wb')\n",
        "pickle.dump(pred_det_regularized_100k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_regularized_100k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZNK6UOzQFfN",
        "colab_type": "code",
        "outputId": "84a8e6e8-bff7-4d3d-8cd7-8f21903bb5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_regularized_150k = model_runner(train_150k_features, train_150k_target)\n",
        "pred_det_regularized_150k = predictor(model_det_regularized_150k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularized Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "155600/155600 [==============================] - 2s 15us/step - loss: 0.0584 - mean_absolute_error: 0.1904\n",
            "Epoch 2/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0498 - mean_absolute_error: 0.1764\n",
            "Epoch 3/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0493 - mean_absolute_error: 0.1754\n",
            "Epoch 4/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0489 - mean_absolute_error: 0.1745\n",
            "Epoch 5/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0487 - mean_absolute_error: 0.1741\n",
            "Epoch 6/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0485 - mean_absolute_error: 0.1736\n",
            "Epoch 7/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0484 - mean_absolute_error: 0.1736\n",
            "Epoch 8/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0483 - mean_absolute_error: 0.1733\n",
            "Epoch 9/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1734\n",
            "Epoch 10/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1731\n",
            "Epoch 11/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1730\n",
            "Epoch 12/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1730\n",
            "Epoch 13/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1729\n",
            "Epoch 14/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1727\n",
            "Epoch 15/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1728\n",
            "Epoch 16/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1727\n",
            "Epoch 17/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1728\n",
            "Epoch 18/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1727\n",
            "Epoch 19/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1725\n",
            "Epoch 20/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1727\n",
            "Epoch 21/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1725\n",
            "Epoch 22/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1725\n",
            "Epoch 23/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 24/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1725\n",
            "Epoch 25/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 26/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1725\n",
            "Epoch 27/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 28/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1723\n",
            "Epoch 29/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 30/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 31/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1724\n",
            "Epoch 32/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 33/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1721\n",
            "Epoch 34/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1723\n",
            "Epoch 35/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1722\n",
            "Epoch 36/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 37/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 38/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 39/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 40/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 41/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 42/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1723\n",
            "Epoch 43/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1722\n",
            "Epoch 44/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 45/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 46/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 47/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 48/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 49/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 50/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 51/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 52/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 53/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 54/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 55/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 56/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 57/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 58/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 59/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 60/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 61/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 62/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 63/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 64/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 65/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 66/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 67/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 68/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 69/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 70/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 71/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 72/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 73/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 74/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 75/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 76/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 77/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 78/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 79/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 80/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 81/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 82/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 83/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 84/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 85/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 86/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 87/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 88/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 89/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 90/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 91/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 92/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 93/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 94/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 95/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 96/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1717\n",
            "Epoch 97/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 98/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 99/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 100/100\n",
            "155600/155600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "40000/40000 [==============================] - 2s 39us/step\n",
            "0.04826874986582595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "om6tbVpe0pQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pickle\n",
        "outfile = open('pred_det_regularized_150k.pickle','wb')\n",
        "pickle.dump(pred_det_regularized_150k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_regularized_150k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmhobMLE0pUk",
        "colab_type": "code",
        "outputId": "ea6540e8-1d27-4c3d-d0b2-2ec5b9ad727b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_regularized_200k= model_runner(train_200k_features, train_200k_target)\n",
        "pred_det_regularized_200k= predictor(model_det_regularized_200k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularized Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "205600/205600 [==============================] - 3s 14us/step - loss: 0.0557 - mean_absolute_error: 0.1861\n",
            "Epoch 2/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0493 - mean_absolute_error: 0.1752\n",
            "Epoch 3/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0488 - mean_absolute_error: 0.1741\n",
            "Epoch 4/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0485 - mean_absolute_error: 0.1736\n",
            "Epoch 5/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0484 - mean_absolute_error: 0.1735\n",
            "Epoch 6/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0482 - mean_absolute_error: 0.1730\n",
            "Epoch 7/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1729\n",
            "Epoch 8/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1729\n",
            "Epoch 9/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1727\n",
            "Epoch 10/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0479 - mean_absolute_error: 0.1726\n",
            "Epoch 11/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 12/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 13/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1724\n",
            "Epoch 14/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1726\n",
            "Epoch 15/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1724\n",
            "Epoch 16/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 17/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 18/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 19/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1723\n",
            "Epoch 20/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 21/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 22/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 23/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 24/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 25/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 26/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 27/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 28/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 29/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 30/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 31/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 32/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 33/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 34/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1718\n",
            "Epoch 35/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 36/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 37/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 38/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 39/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 40/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 41/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 42/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 43/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 44/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 45/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 46/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 47/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 48/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 49/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 50/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 51/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 52/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 53/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 54/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 55/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 56/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 57/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 58/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 59/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 60/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 61/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 62/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 63/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 64/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 65/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 66/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 67/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1719\n",
            "Epoch 68/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 69/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 70/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 71/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 72/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 73/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 74/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 75/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 76/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 77/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 78/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 79/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 80/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 81/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 82/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 83/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 84/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 85/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 86/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 87/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 88/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 89/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 90/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 91/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 92/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 93/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 94/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 95/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 96/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 97/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 98/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 99/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 100/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "40000/40000 [==============================] - 2s 43us/step\n",
            "0.04805198189159775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CYXppXnV0pYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "outfile = open('pred_det_regularized_200k.pickle','wb')\n",
        "pickle.dump(pred_det_regularized_200k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_regularized_200k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z-17AjE0pcg",
        "colab_type": "code",
        "outputId": "33f6cb17-5563-4ede-fb43-5aad7a230fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_regularized_240k = model_runner(train_240k_features, train_240k_target)\n",
        "pred_det_regularized_240k = predictor(model_det_regularized_240k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularized Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(200, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "245600/245600 [==============================] - 4s 15us/step - loss: 0.0545 - mean_absolute_error: 0.1837\n",
            "Epoch 2/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0491 - mean_absolute_error: 0.1744\n",
            "Epoch 3/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0486 - mean_absolute_error: 0.1736\n",
            "Epoch 4/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0483 - mean_absolute_error: 0.1731\n",
            "Epoch 5/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0481 - mean_absolute_error: 0.1726\n",
            "Epoch 6/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0480 - mean_absolute_error: 0.1727\n",
            "Epoch 7/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1723\n",
            "Epoch 8/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0478 - mean_absolute_error: 0.1723\n",
            "Epoch 9/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
            "Epoch 10/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0477 - mean_absolute_error: 0.1721\n",
            "Epoch 11/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 12/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1721\n",
            "Epoch 13/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1720\n",
            "Epoch 14/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 15/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0476 - mean_absolute_error: 0.1719\n",
            "Epoch 16/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 17/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 18/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 19/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 20/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 21/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 22/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 23/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 24/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 25/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 26/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 27/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1718\n",
            "Epoch 28/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 29/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1715\n",
            "Epoch 30/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 31/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 32/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 33/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 34/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 35/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 36/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 37/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 38/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 39/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 40/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 41/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 42/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 43/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 44/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 45/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 46/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 47/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 48/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1717\n",
            "Epoch 49/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 50/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 51/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 52/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 53/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 54/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 55/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 56/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 57/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1716\n",
            "Epoch 58/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 59/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 60/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 61/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 62/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 63/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 64/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 65/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 66/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 67/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 68/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 69/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 70/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 71/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 72/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0475 - mean_absolute_error: 0.1716\n",
            "Epoch 73/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 74/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 75/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 76/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 77/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 78/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 79/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 80/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 81/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 82/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 83/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 84/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 85/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 86/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1715\n",
            "Epoch 87/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 88/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 89/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 90/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 91/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 92/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 93/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 94/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 95/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 96/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "Epoch 97/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 98/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 99/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1713\n",
            "Epoch 100/100\n",
            "245600/245600 [==============================] - 3s 11us/step - loss: 0.0474 - mean_absolute_error: 0.1714\n",
            "40000/40000 [==============================] - 2s 44us/step\n",
            "0.04819988194800458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEuLhURl0pgm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pickle\n",
        "outfile = open('pred_det_regularized_240k.pickle','wb')\n",
        "pickle.dump(pred_det_regularized_240k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_regularized_240k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G23D4-fP0plQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ao63RhC30ppg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxIAkTghnJlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}