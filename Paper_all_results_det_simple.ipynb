{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paper_all_results_det_simple.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailuj/BayesianDeepLearning/blob/playground/Paper_all_results_det_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C9uyVyt2s5Mq",
        "colab_type": "code",
        "outputId": "5252ffa0-042f-4a22-c131-6d96db424080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YoO-pMrlgdov",
        "colab_type": "code",
        "outputId": "406b3308-dcd8-4cc1-ed35-b259d9813ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/data_sets\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_set_40k.csv    train_set_150k.csv\ttrain_set_240k.csv\n",
            "train_set_100k.csv  train_set_200k.csv\ttrain_set_60k.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TKhRgPkztNrT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_40k = pd.read_csv('/content/drive/My Drive/data_sets/test_set_40k.csv')\n",
        "train_60k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_60k.csv')\n",
        "train_100k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_100k.csv')\n",
        "train_150k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_150k.csv')\n",
        "train_200k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_200k.csv')\n",
        "train_240k = pd.read_csv('/content/drive/My Drive/data_sets/train_set_240k.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVLRbu1Vlm-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full = train_240k.append(test_40k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37Yt0TZ2mZvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full = full[['int_rate','loan_amnt','purpose', 'profit_rate']]\n",
        "full_features = full[['int_rate','loan_amnt','purpose']]\n",
        "full_features = pd.get_dummies(full_features)\n",
        "full_target = full[['profit_rate']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VxAcqIltSQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(x):\n",
        "  from sklearn import preprocessing\n",
        "  x = x.dropna()\n",
        " \n",
        "  x_features = x[['int_rate','loan_amnt','purpose']]\n",
        "  x_features = pd.get_dummies(x_features)\n",
        "  x_target = x[['profit_rate']]\n",
        "\n",
        "  scaler_features = preprocessing.MinMaxScaler().fit(full_features)\n",
        "  x_features = scaler_features.transform(x_features)\n",
        "  \n",
        "  scaler_target = preprocessing.MinMaxScaler().fit(full_target)\n",
        "  x_target = scaler_target.transform(x_target)\n",
        "  \n",
        "  return (x_features, x_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_L6cIU8lbbeg",
        "colab_type": "code",
        "outputId": "7aa38a1e-d123-40e1-c58b-1e00db247d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "((test_40k_features,test_40k_target),\n",
        " (train_60k_features,train_60k_target),\n",
        " (train_100k_features,train_100k_target),\n",
        " (train_150k_features,train_150k_target),\n",
        " (train_200k_features,train_200k_target),\n",
        " (train_240k_features,train_240k_target)) = (preprocess(test_40k), \n",
        "                                             preprocess(train_60k), \n",
        "                                             preprocess(train_100k), \n",
        "                                             preprocess(train_150k), \n",
        "                                             preprocess(train_200k), \n",
        "                                             preprocess(train_240k)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qi2RQYntc2CN",
        "colab_type": "code",
        "outputId": "6c6f6ec3-3a95-4d83-da3e-bace3d10aa94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "((test_40k_features.shape,test_40k_target.shape),\n",
        " (train_60k_features.shape,train_60k_target.shape),\n",
        " (train_100k_features.shape,train_100k_target.shape),\n",
        " (train_150k_features.shape,train_150k_target.shape),\n",
        " (train_200k_features.shape,train_200k_target.shape),\n",
        " (train_240k_features.shape,train_240k_target.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((40000, 16), (40000, 1)),\n",
              " ((65600, 16), (65600, 1)),\n",
              " ((105600, 16), (105600, 1)),\n",
              " ((155600, 16), (155600, 1)),\n",
              " ((205600, 16), (205600, 1)),\n",
              " ((245600, 16), (245600, 1)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "RH2IrD6eQH_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modeling\n"
      ]
    },
    {
      "metadata": {
        "id": "3F6LrpwHe46R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model as mcModel\n",
        "from keras import Input as mcInput\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def architecture(model_type, h_cells, n_hidden, input_dim, dropout_prob, reg):\n",
        "  \n",
        "  if model_type == 'deterministic_simple':\n",
        "    from keras.models import Sequential as seq1\n",
        "    from keras.layers import Dropout as drop1\n",
        "    from keras.layers import Dense as dense1\n",
        "    \n",
        "    model1 = seq1()\n",
        "    model1.add(dense1(h_cells, input_dim = input_dim, activation='relu'))\n",
        "    model1.add(dense1(h_cells, activation='relu'))\n",
        "    model1.add(dense1(1))\n",
        "    return model1\n",
        "  \n",
        "\n",
        "def model_runner(X_train, y_train, X_test=test_40k_features, y_test=test_40k_target,\n",
        "                dropout_prob=0.20, n_epochs=100, tau=1.0, batch_size=500, \n",
        "                lengthscale=1e-2, n_hidden=[100,100], h_cells=100):\n",
        "  \n",
        "  input_dim = X_train.shape[1]\n",
        "  N = X_train.shape[0]\n",
        "  reg = lengthscale**2 * (1 - dropout_prob) / (2. * N * tau)\n",
        "\n",
        "  print('Simple Deterministic NN fit')\n",
        "  model_det_simple = architecture(model_type = 'deterministic_simple', \n",
        "                                  h_cells= h_cells, n_hidden=n_hidden, input_dim=input_dim, \n",
        "                                  dropout_prob=dropout_prob, reg=reg)\n",
        "  \n",
        "  model_det_simple.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "  model_det_simple.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epochs, verbose=1)\n",
        "  \n",
        "  \n",
        "  \n",
        "  return (model_det_simple)\n",
        "\n",
        "def predictor(model_det_simple, \n",
        "              X_test=test_40k_features, y_test = test_40k_target, T = 1000):\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  import numpy as np\n",
        "  \n",
        "  pred_det_simple = model_det_simple.predict(X_test, verbose=1)\n",
        "  mse_det_simple = mean_squared_error(pred_det_simple, y_test)\n",
        "  print(mse_det_simple)\n",
        "  \n",
        "  \n",
        "  \n",
        "  return (pred_det_simple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuNiKp0EQGwf",
        "colab_type": "code",
        "outputId": "526eaad7-1f9a-4c9e-e75a-4211ae8524ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_simple_60k = model_runner(train_60k_features, train_60k_target)\n",
        "pred_det_simple_60k = predictor(model_det_simple_60k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "65600/65600 [==============================] - 1s 14us/step - loss: 0.0570 - mean_absolute_error: 0.1857\n",
            "Epoch 2/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1713\n",
            "Epoch 3/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1712\n",
            "Epoch 4/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1714\n",
            "Epoch 5/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 6/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1711\n",
            "Epoch 7/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 8/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1710\n",
            "Epoch 9/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0478 - mean_absolute_error: 0.1712\n",
            "Epoch 10/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1709\n",
            "Epoch 11/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1712\n",
            "Epoch 12/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 13/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1708\n",
            "Epoch 14/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 15/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1712\n",
            "Epoch 16/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1707\n",
            "Epoch 17/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 18/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 19/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1709\n",
            "Epoch 20/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1705\n",
            "Epoch 21/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 22/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 23/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1710\n",
            "Epoch 24/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1708\n",
            "Epoch 25/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 26/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 27/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1706\n",
            "Epoch 28/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1708\n",
            "Epoch 29/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1710\n",
            "Epoch 30/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 31/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 32/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1706\n",
            "Epoch 33/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 34/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 35/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1705\n",
            "Epoch 36/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 37/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 38/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1705\n",
            "Epoch 39/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 40/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 41/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 42/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 43/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 44/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1706\n",
            "Epoch 45/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 46/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1707\n",
            "Epoch 47/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 48/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 49/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 50/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1704\n",
            "Epoch 51/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 52/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 53/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 54/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1704\n",
            "Epoch 55/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 56/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 57/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 58/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 59/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 60/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 61/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 62/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1704\n",
            "Epoch 63/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 64/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 65/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 66/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 67/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 68/100\n",
            "65600/65600 [==============================] - 1s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1704\n",
            "Epoch 69/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 70/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 71/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 72/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1702\n",
            "Epoch 73/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 74/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 75/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1701\n",
            "Epoch 76/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 77/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1702\n",
            "Epoch 78/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 79/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 80/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1702\n",
            "Epoch 81/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 82/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 83/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 84/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 85/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 86/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 87/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 88/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1699\n",
            "Epoch 89/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 90/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 91/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1708\n",
            "Epoch 92/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1699\n",
            "Epoch 93/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 94/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 95/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 96/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 97/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 98/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 99/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 100/100\n",
            "65600/65600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "40000/40000 [==============================] - 1s 32us/step\n",
            "0.047888049917268666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9zMdMMh1Apf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "outfile = open('pred_det_simple_60k.pickle','wb')\n",
        "pickle.dump(pred_det_simple_60k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_simple_60k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VgFnGN6aQFZi",
        "colab_type": "code",
        "outputId": "cf69ce4a-e479-475b-b260-6afd41bebc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_simple_100k = model_runner(train_100k_features, train_100k_target)\n",
        "pred_det_simple_100k = predictor(model_det_simple_100k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "105600/105600 [==============================] - 1s 13us/step - loss: 0.0521 - mean_absolute_error: 0.1783\n",
            "Epoch 2/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 3/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1708\n",
            "Epoch 4/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 5/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 6/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 7/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 8/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1706\n",
            "Epoch 9/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1706\n",
            "Epoch 10/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 11/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1705\n",
            "Epoch 12/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 13/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1702\n",
            "Epoch 14/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1705\n",
            "Epoch 15/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 16/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 17/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1703\n",
            "Epoch 18/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1702\n",
            "Epoch 19/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 20/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 21/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 22/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 23/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 24/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 25/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 26/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 27/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 28/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 29/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 30/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 31/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 32/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1701\n",
            "Epoch 33/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 34/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 35/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 36/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1703\n",
            "Epoch 37/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 38/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 39/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 40/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 41/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1700\n",
            "Epoch 42/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 43/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 44/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 45/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 46/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 47/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 48/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1701\n",
            "Epoch 49/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1700\n",
            "Epoch 50/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1699\n",
            "Epoch 51/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 52/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 53/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 54/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1698\n",
            "Epoch 55/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 56/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 57/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 58/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 59/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 60/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1696\n",
            "Epoch 61/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 62/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 63/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 64/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 65/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 66/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 67/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 68/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 69/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 70/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 71/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 72/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 73/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 74/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 75/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 76/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 77/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 78/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 79/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 80/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 81/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 82/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 83/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 84/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 85/100\n",
            "105600/105600 [==============================] - 1s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 86/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 87/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 88/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 89/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 90/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 91/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 92/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 93/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 94/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 95/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 96/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 97/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1695\n",
            "Epoch 98/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 99/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 100/100\n",
            "105600/105600 [==============================] - 1s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "40000/40000 [==============================] - 1s 33us/step\n",
            "0.04771027138347004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "drTF_nHG1aeB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "outfile = open('pred_det_simple_100k.pickle','wb')\n",
        "pickle.dump(pred_det_simple_100k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_simple_100k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZNK6UOzQFfN",
        "colab_type": "code",
        "outputId": "448c2b38-2eb2-4dc2-8cf5-020c162233f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_simple_150k= model_runner(train_150k_features, train_150k_target)\n",
        "pred_det_simple_150k = predictor(model_det_simple_150k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "155600/155600 [==============================] - 2s 12us/step - loss: 0.0529 - mean_absolute_error: 0.1792\n",
            "Epoch 2/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1714\n",
            "Epoch 3/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1713\n",
            "Epoch 4/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1712\n",
            "Epoch 5/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1712\n",
            "Epoch 6/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1714\n",
            "Epoch 7/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1713\n",
            "Epoch 8/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1712\n",
            "Epoch 9/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 10/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0477 - mean_absolute_error: 0.1713\n",
            "Epoch 11/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1711\n",
            "Epoch 12/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1712\n",
            "Epoch 13/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1712\n",
            "Epoch 14/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 15/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 16/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1711\n",
            "Epoch 17/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 18/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1711\n",
            "Epoch 19/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 20/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 21/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 22/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1711\n",
            "Epoch 23/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 24/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 25/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 26/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1710\n",
            "Epoch 27/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1710\n",
            "Epoch 28/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 29/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1710\n",
            "Epoch 30/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 31/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1710\n",
            "Epoch 32/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 33/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 34/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 35/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 36/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 37/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 38/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 39/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 40/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1706\n",
            "Epoch 41/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 42/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1705\n",
            "Epoch 43/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 44/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 45/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1705\n",
            "Epoch 46/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 47/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 48/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 49/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 50/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 51/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 52/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 53/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1703\n",
            "Epoch 54/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 55/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 56/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 57/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 58/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 59/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1703\n",
            "Epoch 60/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 61/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 62/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 63/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 64/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 65/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 66/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 67/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 68/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 69/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 70/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 71/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 72/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 73/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 74/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 75/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 76/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 77/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1699\n",
            "Epoch 78/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 79/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1701\n",
            "Epoch 80/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 81/100\n",
            "155600/155600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 82/100\n",
            "155600/155600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1701\n",
            "Epoch 83/100\n",
            "155600/155600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 84/100\n",
            "155600/155600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 85/100\n",
            "155600/155600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1701\n",
            "Epoch 86/100\n",
            "155600/155600 [==============================] - 1s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 87/100\n",
            "155600/155600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1701\n",
            "Epoch 88/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 89/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 90/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 91/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 92/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 93/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 94/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 95/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 96/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 97/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 98/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 99/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 100/100\n",
            "155600/155600 [==============================] - 1s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "40000/40000 [==============================] - 1s 34us/step\n",
            "0.047592177727944024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "om6tbVpe0pQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "outfile = open('pred_det_simple_150k.pickle','wb')\n",
        "pickle.dump(pred_det_simple_150k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_simple_150k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmhobMLE0pUk",
        "colab_type": "code",
        "outputId": "07208def-0636-4f7d-92d6-89a7fac30ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_simple_200k = model_runner(train_200k_features, train_200k_target)\n",
        "pred_det_simple_200k = predictor(model_det_simple_200k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "205600/205600 [==============================] - 2s 11us/step - loss: 0.0498 - mean_absolute_error: 0.1747\n",
            "Epoch 2/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1713\n",
            "Epoch 3/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1710\n",
            "Epoch 4/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1711\n",
            "Epoch 5/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 6/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0476 - mean_absolute_error: 0.1711\n",
            "Epoch 7/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 8/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1711\n",
            "Epoch 9/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 10/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1710\n",
            "Epoch 11/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 12/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1709\n",
            "Epoch 13/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 14/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 15/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1709\n",
            "Epoch 16/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 17/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1708\n",
            "Epoch 18/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 19/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 20/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1707\n",
            "Epoch 21/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 22/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1706\n",
            "Epoch 23/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1705\n",
            "Epoch 24/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 25/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 26/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 27/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 28/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 29/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 30/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 31/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 32/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 33/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 34/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 35/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 36/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 37/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 38/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 39/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 40/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 41/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 42/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 43/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 44/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 45/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 46/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 47/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1701\n",
            "Epoch 48/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 49/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 50/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 51/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 52/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 53/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 54/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 55/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 56/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 57/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 58/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 59/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 60/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 61/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 62/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 63/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 64/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 65/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 66/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 67/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 68/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1699\n",
            "Epoch 69/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 70/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 71/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 72/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 73/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 74/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 75/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 76/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 77/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 78/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 79/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 80/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1698\n",
            "Epoch 81/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 82/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 83/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 84/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1698\n",
            "Epoch 85/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1698\n",
            "Epoch 86/100\n",
            "205600/205600 [==============================] - 2s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 87/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 88/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1699\n",
            "Epoch 89/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 90/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 91/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 92/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1698\n",
            "Epoch 93/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 94/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 95/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 96/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 97/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 98/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1698\n",
            "Epoch 99/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 100/100\n",
            "205600/205600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "40000/40000 [==============================] - 1s 36us/step\n",
            "0.04756789794261089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CYXppXnV0pYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "outfile = open('pred_det_simple_200k.pickle','wb')\n",
        "pickle.dump(pred_det_simple_200k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('pred_det_simple_200k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z-17AjE0pcg",
        "colab_type": "code",
        "outputId": "d8a0a36e-15ef-4cc7-fb97-66c74d5e2cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "cell_type": "code",
      "source": [
        "model_det_simple_240k = model_runner(train_240k_features, train_240k_target)\n",
        "pred_det_simple_240k = predictor(model_det_simple_240k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Deterministic NN fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "245600/245600 [==============================] - 3s 12us/step - loss: 0.0494 - mean_absolute_error: 0.1739\n",
            "Epoch 2/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0475 - mean_absolute_error: 0.1708\n",
            "Epoch 3/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 4/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1708\n",
            "Epoch 5/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0475 - mean_absolute_error: 0.1707\n",
            "Epoch 6/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1706\n",
            "Epoch 7/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 8/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1707\n",
            "Epoch 9/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 10/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 11/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0474 - mean_absolute_error: 0.1705\n",
            "Epoch 12/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 13/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 14/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 15/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1705\n",
            "Epoch 16/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 17/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0473 - mean_absolute_error: 0.1704\n",
            "Epoch 18/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1705\n",
            "Epoch 19/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 20/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1704\n",
            "Epoch 21/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 22/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 23/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1702\n",
            "Epoch 24/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0472 - mean_absolute_error: 0.1703\n",
            "Epoch 25/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1702\n",
            "Epoch 26/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0471 - mean_absolute_error: 0.1700\n",
            "Epoch 27/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1700\n",
            "Epoch 28/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 29/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 30/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1698\n",
            "Epoch 31/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 32/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 33/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 34/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 35/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 36/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 37/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 38/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 39/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0470 - mean_absolute_error: 0.1696\n",
            "Epoch 40/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1697\n",
            "Epoch 41/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0470 - mean_absolute_error: 0.1697\n",
            "Epoch 42/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 43/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 44/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 45/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 46/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 47/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1696\n",
            "Epoch 48/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 49/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 50/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 51/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 52/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 53/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 54/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 55/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 56/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1693\n",
            "Epoch 57/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 58/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 59/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 60/100\n",
            "245600/245600 [==============================] - 2s 10us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 61/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1695\n",
            "Epoch 62/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 63/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 64/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1695\n",
            "Epoch 65/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0469 - mean_absolute_error: 0.1694\n",
            "Epoch 66/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 67/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 68/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 69/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 70/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 71/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 72/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 73/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 74/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 75/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 76/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 77/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 78/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 79/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 80/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 81/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 82/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 83/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 84/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 85/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 86/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 87/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 88/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 89/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 90/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 91/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 92/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1694\n",
            "Epoch 93/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 94/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1692\n",
            "Epoch 95/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 96/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 97/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 98/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 99/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "Epoch 100/100\n",
            "245600/245600 [==============================] - 2s 9us/step - loss: 0.0468 - mean_absolute_error: 0.1693\n",
            "40000/40000 [==============================] - 1s 36us/step\n",
            "0.047531827266043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEuLhURl0pgm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "outfile = open('pred_det_simple_240k.pickle','wb')\n",
        "pickle.dump(pred_det_simple_240k,outfile)\n",
        "outfile.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('pred_det_simple_240k.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G23D4-fP0plQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ao63RhC30ppg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}